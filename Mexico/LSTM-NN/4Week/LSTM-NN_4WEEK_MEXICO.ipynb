{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM-NN_4WEEK_MEXICO.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"6SQxKafBddjL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"73f759cf-0354-462c-e2bc-c529775c85d2","executionInfo":{"status":"ok","timestamp":1550826571208,"user_tz":360,"elapsed":493,"user":{"displayName":"Kevin Islas Abud","photoUrl":"","userId":"17803260883912783595"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"jGqd9KGnc2Qt","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import mean_squared_error\n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HegpfncUc2RA","colab_type":"code","colab":{}},"cell_type":"code","source":["files = os.listdir(\"drive/My Drive/ziknet-trends-rolling/data/Mexico/processed_data\")\n","weeks_ahead = 4"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tXCw51Twc2RK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":752},"outputId":"766628aa-a2ef-47e1-e7a2-cebe168d2dad","executionInfo":{"status":"ok","timestamp":1550826572406,"user_tz":360,"elapsed":1640,"user":{"displayName":"Kevin Islas Abud","photoUrl":"","userId":"17803260883912783595"}}},"cell_type":"code","source":["datasets = {}\n","for file in files:\n","    datasets[file] = pd.read_csv(\"drive/My Drive/ziknet-trends-rolling/data/Mexico/processed_data/{}\".format(file))\n","    datasets[file][\"Searches\"] /= 100\n","    print(file)\n","    print(datasets[file].tail())\n","    print(\"Number of observations: \", len(datasets[file]))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Chiapas_2016-2017.csv\n","           Date  Searches  Cases\n","99   25/11/2017      0.00      0\n","100  02/12/2017      0.05      0\n","101  09/12/2017      0.00      0\n","102  16/12/2017      0.00      0\n","103  23/12/2017      0.00      0\n","Number of observations:  104\n","Guerrero_2016-2017.csv\n","           Date  Searches  Cases\n","99   25/11/2017      0.07      0\n","100  02/12/2017      0.06      3\n","101  09/12/2017      0.00      0\n","102  16/12/2017      0.12      0\n","103  23/12/2017      0.42      0\n","Number of observations:  104\n","NuevoLeon_2016-2017.csv\n","           Date  Searches  Cases\n","99   25/11/2017      0.08      2\n","100  02/12/2017      0.06      2\n","101  09/12/2017      0.01      6\n","102  16/12/2017      0.04      0\n","103  23/12/2017      0.36      0\n","Number of observations:  104\n","Veracruz_2016-2017.csv\n","           Date  Searches  Cases\n","99   25/11/2017      0.05      5\n","100  02/12/2017      0.03      3\n","101  09/12/2017      0.04      5\n","102  16/12/2017      0.07      3\n","103  23/12/2017      0.00      3\n","Number of observations:  104\n","Yucatan_2016-2017.csv\n","           Date  Searches  Cases\n","99   25/11/2017      0.02      0\n","100  02/12/2017      0.04      0\n","101  09/12/2017      0.00      0\n","102  16/12/2017      0.00      0\n","103  23/12/2017      0.00      0\n","Number of observations:  104\n"],"name":"stdout"}]},{"metadata":{"id":"ZpwZmV1Xc2RZ","colab_type":"code","colab":{}},"cell_type":"code","source":["def series_to_supervised(df, outputColumn, n_in=1, n_out=1, dropnan=True):\n","    n_vars = df.shape[1]\n","    cols, names = list(), list()\n","    # input sequence (t-n, ... t-1)\n","    for i in range(n_in, 0, -1):\n","        cols.append(df.shift(i))\n","        names += [(\"{}(t-{})\".format(col, i)) for col in df.columns]\n","\n","    # Append next observation[outputColumn] at n_out obs\n","    cols.append(df[outputColumn].shift(-n_out+1))\n","    names+=[outputColumn + \"(t+{})\".format(n_out-1)]\n","\n","    # put it all together\n","    agg = pd.concat(cols, axis=1)\n","    agg.columns = names\n","    # drop rows with NaN values\n","    if dropnan:\n","        agg.dropna(inplace=True)\n","    return agg"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iUC8SIYyc2Rf","colab_type":"code","colab":{}},"cell_type":"code","source":["def getXY(dataset, state, weeksAhead):\n","    n_features = dataset.shape[1]\n","    \n","    n_weeks = 4\n","    reframed = series_to_supervised(dataset, \"Cases\",  n_weeks, weeksAhead)\n","    values = reframed.values\n","    \n","    totalFeatures = values.shape[1]\n","\n","    x,y = values[:, :totalFeatures-1], values[:, totalFeatures-1] #Y is the last column, X is all the previous columns \n","\n","    x = x.reshape((x.shape[0], n_weeks, n_features)) # Reshape as 3-D\n","    return x, y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BAhkbQZ3c2Rn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"1615e8b5-1bf7-4d58-b360-4f392cafd8e1","executionInfo":{"status":"ok","timestamp":1550826578690,"user_tz":360,"elapsed":7885,"user":{"displayName":"Kevin Islas Abud","photoUrl":"","userId":"17803260883912783595"}}},"cell_type":"code","source":["import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Flatten, Dense, LSTM, BatchNormalization\n","from keras.optimizers import Adam\n","from keras.layers.merge import concatenate\n","from keras.constraints import non_neg\n","def LSTM_NN_Model():\n","    input_layer = Input(shape=(4,2))\n","    \n","    \n","    b1_out = LSTM(16, return_sequences=False)(input_layer)\n","\n","    b2_out = Dense(128, activation=\"relu\", kernel_regularizer=\"l2\")(input_layer)\n","    b2_out = Flatten()(b2_out)\n","\n","    concatenated = concatenate([b1_out, b2_out])\n","    \n","    out = Dense(8, activation=\"relu\", kernel_regularizer=\"l2\")(concatenated)\n","    out = Dense(8, activation=\"relu\", kernel_regularizer=\"l2\")(out)\n","#     out = Dense(1, activation=\"linear\", kernel_constraint=non_neg(), name='output_layer')(out)\n","    out = Dense(1, activation=\"linear\", name='output_layer')(out)\n","\n","    model = Model([input_layer], out)\n","    model.compile(loss=[\"mse\"], optimizer=Adam(0.0001), metrics=[\"mae\"])\n","\n","    return model"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"8dz6XCrvc2Rx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":239},"outputId":"9fd24f74-ea93-4830-e6ba-1de6fea37730","executionInfo":{"status":"ok","timestamp":1550829220552,"user_tz":360,"elapsed":2649727,"user":{"displayName":"Kevin Islas Abud","photoUrl":"","userId":"17803260883912783595"}}},"cell_type":"code","source":["for file in datasets:\n","    dataset = datasets[file]\n","    x, y = getXY(dataset[[\"Searches\", \"Cases\"]], \"\", weeks_ahead)\n","    model = LSTM_NN_Model()\n","    \n","    xDim1 = x[0].shape[0]\n","    xDim2 = x[0].shape[1]\n","    \n","    splitIndex = len(x) - 52\n","\n","    train_X = x[:splitIndex]\n","    train_y = y[:splitIndex]\n","\n","    test_y = y[splitIndex:]\n","    outDataset = pd.DataFrame()\n","    outDataset[\"Observerd\"] = test_y\n","\n","    model.fit(\n","        train_X,\n","        train_y,\n","        epochs=200,\n","        batch_size=4,\n","        verbose=0,\n","        shuffle=False)\n","\n","    predicted_y_history = []\n","\n","    while(splitIndex < len(y)):\n","        predicted_y = \\\n","            model.predict(x[splitIndex].reshape(1, xDim1, xDim2))[0]\n","\n","        model.fit(\n","            x[:splitIndex+1],\n","            y[:splitIndex+1],\n","            epochs=40,\n","            batch_size=4,\n","            verbose=0,\n","            shuffle=False)\n","\n","        predicted_y_history.append(predicted_y[0])\n","        splitIndex += 1\n","\n","    outDataset[\"PREDICTED\"] = predicted_y_history\n","    print(\"{} RMSE: {}\".format(file, mean_squared_error(test_y, predicted_y_history)))\n","    outDataset.to_csv(file)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Chiapas_2016-2017.csv RMSE: 29.246202664092284\n","Guerrero_2016-2017.csv RMSE: 7.4740203020861395\n","NuevoLeon_2016-2017.csv RMSE: 2251.303877589863\n","Veracruz_2016-2017.csv RMSE: 477.42024467528756\n","Yucatan_2016-2017.csv RMSE: 16.322400634476566\n"],"name":"stdout"}]}]}