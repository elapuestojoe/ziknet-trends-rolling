{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM-NN_3WEEK_MEXICO.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"o15Dl0iNdTtd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"c3da72df-f84a-4af5-8d26-5712855db25f","executionInfo":{"status":"ok","timestamp":1550826553217,"user_tz":360,"elapsed":443,"user":{"displayName":"Kevin Islas Abud","photoUrl":"","userId":"17803260883912783595"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"6fzWyCaZc0N7","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import mean_squared_error\n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hNDg-X_4c0OO","colab_type":"code","colab":{}},"cell_type":"code","source":["files = os.listdir(\"drive/My Drive/ziknet-trends-rolling/data/Mexico/processed_data\")\n","weeks_ahead = 3"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m16xyNEJc0OX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":752},"outputId":"0d295a64-7b78-4bbc-912e-d90a082a73f9","executionInfo":{"status":"ok","timestamp":1550826553742,"user_tz":360,"elapsed":876,"user":{"displayName":"Kevin Islas Abud","photoUrl":"","userId":"17803260883912783595"}}},"cell_type":"code","source":["datasets = {}\n","for file in files:\n","    datasets[file] = pd.read_csv(\"drive/My Drive/ziknet-trends-rolling/data/Mexico/processed_data/{}\".format(file))\n","    datasets[file][\"Searches\"] /= 100\n","    print(file)\n","    print(datasets[file].tail())\n","    print(\"Number of observations: \", len(datasets[file]))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Chiapas_2016-2017.csv\n","           Date  Searches  Cases\n","99   25/11/2017      0.00      0\n","100  02/12/2017      0.05      0\n","101  09/12/2017      0.00      0\n","102  16/12/2017      0.00      0\n","103  23/12/2017      0.00      0\n","Number of observations:  104\n","Guerrero_2016-2017.csv\n","           Date  Searches  Cases\n","99   25/11/2017      0.07      0\n","100  02/12/2017      0.06      3\n","101  09/12/2017      0.00      0\n","102  16/12/2017      0.12      0\n","103  23/12/2017      0.42      0\n","Number of observations:  104\n","NuevoLeon_2016-2017.csv\n","           Date  Searches  Cases\n","99   25/11/2017      0.08      2\n","100  02/12/2017      0.06      2\n","101  09/12/2017      0.01      6\n","102  16/12/2017      0.04      0\n","103  23/12/2017      0.36      0\n","Number of observations:  104\n","Veracruz_2016-2017.csv\n","           Date  Searches  Cases\n","99   25/11/2017      0.05      5\n","100  02/12/2017      0.03      3\n","101  09/12/2017      0.04      5\n","102  16/12/2017      0.07      3\n","103  23/12/2017      0.00      3\n","Number of observations:  104\n","Yucatan_2016-2017.csv\n","           Date  Searches  Cases\n","99   25/11/2017      0.02      0\n","100  02/12/2017      0.04      0\n","101  09/12/2017      0.00      0\n","102  16/12/2017      0.00      0\n","103  23/12/2017      0.00      0\n","Number of observations:  104\n"],"name":"stdout"}]},{"metadata":{"id":"pUHDRU5xc0Ok","colab_type":"code","colab":{}},"cell_type":"code","source":["def series_to_supervised(df, outputColumn, n_in=1, n_out=1, dropnan=True):\n","    n_vars = df.shape[1]\n","    cols, names = list(), list()\n","    # input sequence (t-n, ... t-1)\n","    for i in range(n_in, 0, -1):\n","        cols.append(df.shift(i))\n","        names += [(\"{}(t-{})\".format(col, i)) for col in df.columns]\n","\n","    # Append next observation[outputColumn] at n_out obs\n","    cols.append(df[outputColumn].shift(-n_out+1))\n","    names+=[outputColumn + \"(t+{})\".format(n_out-1)]\n","\n","    # put it all together\n","    agg = pd.concat(cols, axis=1)\n","    agg.columns = names\n","    # drop rows with NaN values\n","    if dropnan:\n","        agg.dropna(inplace=True)\n","    return agg"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GCQnrXaac0Or","colab_type":"code","colab":{}},"cell_type":"code","source":["def getXY(dataset, state, weeksAhead):\n","    n_features = dataset.shape[1]\n","    \n","    n_weeks = 4\n","    reframed = series_to_supervised(dataset, \"Cases\",  n_weeks, weeksAhead)\n","    values = reframed.values\n","    \n","    totalFeatures = values.shape[1]\n","\n","    x,y = values[:, :totalFeatures-1], values[:, totalFeatures-1] #Y is the last column, X is all the previous columns \n","\n","    x = x.reshape((x.shape[0], n_weeks, n_features)) # Reshape as 3-D\n","    return x, y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9gtr03fbc0O0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e65711b1-d981-491b-dc0d-828de76ea6d8","executionInfo":{"status":"ok","timestamp":1550826557156,"user_tz":360,"elapsed":4243,"user":{"displayName":"Kevin Islas Abud","photoUrl":"","userId":"17803260883912783595"}}},"cell_type":"code","source":["import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Flatten, Dense, LSTM, BatchNormalization\n","from keras.optimizers import Adam\n","from keras.layers.merge import concatenate\n","from keras.constraints import non_neg\n","def LSTM_NN_Model():\n","    input_layer = Input(shape=(4,2))\n","    \n","    \n","    b1_out = LSTM(16, return_sequences=False)(input_layer)\n","\n","    b2_out = Dense(128, activation=\"relu\", kernel_regularizer=\"l2\")(input_layer)\n","    b2_out = Flatten()(b2_out)\n","\n","    concatenated = concatenate([b1_out, b2_out])\n","    \n","    out = Dense(8, activation=\"relu\", kernel_regularizer=\"l2\")(concatenated)\n","    out = Dense(8, activation=\"relu\", kernel_regularizer=\"l2\")(out)\n","#     out = Dense(1, activation=\"linear\", kernel_constraint=non_neg(), name='output_layer')(out)\n","    out = Dense(1, activation=\"linear\", name='output_layer')(out)\n","\n","    model = Model([input_layer], out)\n","    model.compile(loss=[\"mse\"], optimizer=Adam(0.0001), metrics=[\"mae\"])\n","\n","    return model"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"HLhUMZ3uc0O9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":239},"outputId":"539c28fc-b681-4006-b2b3-519d8067bcbf","executionInfo":{"status":"ok","timestamp":1550829247766,"user_tz":360,"elapsed":2694832,"user":{"displayName":"Kevin Islas Abud","photoUrl":"","userId":"17803260883912783595"}}},"cell_type":"code","source":["for file in datasets:\n","    dataset = datasets[file]\n","    x, y = getXY(dataset[[\"Searches\", \"Cases\"]], \"\", weeks_ahead)\n","    model = LSTM_NN_Model()\n","    \n","    xDim1 = x[0].shape[0]\n","    xDim2 = x[0].shape[1]\n","    \n","    splitIndex = len(x) - 52\n","\n","    train_X = x[:splitIndex]\n","    train_y = y[:splitIndex]\n","\n","    test_y = y[splitIndex:]\n","    outDataset = pd.DataFrame()\n","    outDataset[\"Observerd\"] = test_y\n","\n","    model.fit(\n","        train_X,\n","        train_y,\n","        epochs=200,\n","        batch_size=4,\n","        verbose=0,\n","        shuffle=False)\n","\n","    predicted_y_history = []\n","\n","    while(splitIndex < len(y)):\n","        predicted_y = \\\n","            model.predict(x[splitIndex].reshape(1, xDim1, xDim2))[0]\n","\n","        model.fit(\n","            x[:splitIndex+1],\n","            y[:splitIndex+1],\n","            epochs=40,\n","            batch_size=4,\n","            verbose=0,\n","            shuffle=False)\n","\n","        predicted_y_history.append(predicted_y[0])\n","        splitIndex += 1\n","\n","    outDataset[\"PREDICTED\"] = predicted_y_history\n","    print(\"{} MSE: {}\".format(file, mean_squared_error(test_y, predicted_y_history)))\n","    outDataset.to_csv(file)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Chiapas_2016-2017.csv MSE: 13.230122703757358\n","Guerrero_2016-2017.csv MSE: 5.301145173108029\n","NuevoLeon_2016-2017.csv MSE: 833.860494598462\n","Veracruz_2016-2017.csv MSE: 336.60585597933846\n","Yucatan_2016-2017.csv MSE: 17.270350802292665\n"],"name":"stdout"}]}]}